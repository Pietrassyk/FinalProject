{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########Starting SCRIPT########\n",
      "Found 3 files in content table\n",
      "Found 3 files in conversations table\n",
      "=======Setup Complete========\n",
      "Performing Job 1/3\n",
      "Current File: AM_101_affirmativeaction_pro.wav\n",
      "File already transcribed\n",
      "Output succesfull\n",
      "File transcription already in content table -> will not append!\n",
      "File transcription already in conversations table -> will not append!\n",
      "--------Job complete--------\n",
      "Performing Job 2/3\n",
      "Current File: DJ_1_ban-video-games_pro.wav\n",
      "File already transcribed\n",
      "Output succesfull\n",
      "File transcription already in content table -> will not append!\n",
      "File transcription already in conversations table -> will not append!\n",
      "--------Job complete--------\n",
      "Performing Job 3/3\n",
      "Current File: EH_1_ban-video-games_pro.wav\n",
      "File already transcribed\n",
      "Output succesfull\n",
      "File transcription already in content table -> will not append!\n",
      "File transcription already in conversations table -> will not append!\n",
      "--------Job complete--------\n",
      "========Finished ETL========\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "########\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import mysql.connector\n",
    "import tpclean.tpclean as tp\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#custom imports\n",
    "from Scripts.config import role, bucket_name, prefix, bucket_path, sub_path\n",
    "from Scripts.etl_functions import find_audios , transcribe_wav , get_pause , files_in_table\n",
    "\n",
    "#establish connection\n",
    "from Scripts.config import host, db\n",
    "from Private.private import user , password \n",
    "\n",
    "\n",
    "#SETUP\n",
    "########\n",
    "print(\"########Starting SCRIPT########\")\n",
    "\n",
    "conn_kwargs = {\"host\":host, \n",
    "               \"user\":user, \n",
    "               \"password\":password}\n",
    "#tp.sql_connect(db,db_type=\"mysql\",**conn_kwargs)\n",
    "conn = mysql.connector.Connect(database = db, **conn_kwargs)\n",
    "c = conn.cursor()\n",
    "\n",
    "#connecting via sqlalchemy because pandas needs an engine to store data in an mysql DB\n",
    "engine = create_engine(f'mysql+pymysql://{user}:{password}@{conn_kwargs[\"host\"]}:3306/{db}')\n",
    "\n",
    "#get content of content and conversation table to check if files exist\n",
    "files_in_content = files_in_table(c,\"content\", \"origin\")\n",
    "files_in_conversations = files_in_table(c,\"conversations\", \"filename\")\n",
    "                    \n",
    "audio_files = find_audios(bucket_name)\n",
    "i=0\n",
    "\n",
    "print(\"=======Setup Complete========\")\n",
    "                       \n",
    "#ETL\n",
    "########\n",
    "for filename in audio_files:\n",
    "    i+=1\n",
    "    print(f\"Performing Job {i}/{len(audio_files)}\")\n",
    "    print(f\"Current File: {filename}\")\n",
    "    job_uri = f\"{bucket_path}/{sub_path}/{filename}\"\n",
    "    trans_json_uri = transcribe_wav(job_uri)[1]\n",
    "\n",
    "    #load json from URL\n",
    "    r = requests.get(trans_json_uri)\n",
    "\n",
    "    #store json\n",
    "    explore = r.json()\n",
    "\n",
    "    #store full text\n",
    "    fulltext = explore[\"results\"][\"transcripts\"][0][\"transcript\"]\n",
    "\n",
    "    #create Dataframe\n",
    "    df = pd.DataFrame(explore[\"results\"][\"items\"])\n",
    "    \n",
    "    #unnest the data using tpclean\n",
    "    df = tp.unnest_df_list(df,[\"alternatives\"])\n",
    "    df = tp.unnest_df_dict(df,[\"alternatives_1\"])\n",
    "    df.rename({\"alternatives_1_confidence\":\"confidence\", \n",
    "               \"alternatives_1_content\": \"content\"}, \n",
    "              axis = \"columns\", inplace = True)\n",
    "    \n",
    "    #convert columns containing numbers into float datatype\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = df[col].astype(\"float\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    #engineer length of word and pauses between words\n",
    "    df[\"length\"] = df.end_time-df.start_time\n",
    "    get_pause(df,\"start_time\",\"end_time\");\n",
    "\n",
    "    #append filename\n",
    "    df[\"origin\"] = filename\n",
    "\n",
    "    #append default speaker for now\n",
    "    df[\"speaker\"] = \"speaker_default\"\n",
    "\n",
    "    #append word \n",
    "    df = df.reset_index().rename({\"index\":\"pos_in_conv\"},axis = \"columns\");\n",
    "            \n",
    "    #check whether file already in the content_table\n",
    "    if not len(set(df.origin.unique()).intersection(files_in_content)):\n",
    "        #append data to DB\n",
    "        print(\"Appending to content table\")\n",
    "        df.to_sql(\"content\",engine, if_exists=\"append\", index = False)\n",
    "    else:\n",
    "        print(\"File transcription already in content table -> will not append!\")\n",
    "        pass\n",
    "    \n",
    "    #load metadata and text into database\n",
    "    #check whether filre is already in the conversations table\n",
    "    if filename in files_in_conversations:\n",
    "        print(\"File transcription already in conversations table -> will not append!\")\n",
    "        print(\"--------Job complete--------\")\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        print(f\"File : {filename} not in conversations table yet.\")\n",
    "        #querry for columms\n",
    "        c.execute(\"DESCRIBE conversations\")\n",
    "        columns = \", \".join(pd.DataFrame(c.fetchall()).iloc[1:,0])\n",
    "        \n",
    "        #extract information from filename\n",
    "        name_split = filename[:-4].split(\"_\")\n",
    "    \n",
    "        #fill values                   \n",
    "        values = [filename,\n",
    "                name_split[-2].lower(), \n",
    "                int(name_split[-1].lower() == \"pro\"), \n",
    "                trans_json_uri, \n",
    "                fulltext]\n",
    "    \n",
    "        #Querry Database\n",
    "        querry = \"\"\"INSERT INTO conversations({}) VALUES (\"{}\",\"{}\",{},\"{}\",\"{}\");\"\"\".format(columns,*values)\n",
    "        c.execute(querry)\n",
    "        conn.commit()\n",
    "        print(\"Appending to Conversation Database\")\n",
    "        print(\"--------Job complete--------\")\n",
    "\n",
    "#close connection\n",
    "conn.close()\n",
    "print(\"========Finished ETL========\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
